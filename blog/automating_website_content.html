<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IN-DL" name="geo.region"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Automating Website Content: A Comparison between Client-Side and Server-Side Automation</title>
<meta content="website automation client-side automation server-side automation JavaScript PHP search engines crawlers web content generation SEO crawler-friendly websites lazy loading DASH video streaming HTML CSS pre-rendering web design" name="keywords"/>
<meta content="This article compares client-side and server-side automation techniques for website content. It covers the roles of search engines and crawlers, client-side automation using JavaScript, and server-side automation using PHP. The discussion includes considerations for making content discoverable by search engines and techniques for optimizing media delivery." name="description"/>
<meta content="Anurag Gupta" name="author"/>
<meta content="Automating Website Content: A Comparison between Client-Side and Server-Side Automation" property="og:title"/>
<meta content="Personal website" property="og:type"/>
<meta content="http://www.anuragg.in" property="og:url"/>
<meta content="Automating Website Content: A Comparison between Client-Side and Server-Side Automation" property="og:description"/>
<meta content="images/anurag.png" property="og:image"/>
<meta content="Anurag Gupta" property="og:site_name"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="images/anurag.png" name="twitter:image"/>
<meta content="Automating Website Content: A Comparison between Client-Side and Server-Side Automation" name="twitter:title"/>
<meta content="This article compares client-side and server-side automation techniques for website content. It covers the roles of search engines and crawlers, client-side automation using JavaScript, and server-side automation using PHP. The discussion includes considerations for making content discoverable by search engines and techniques for optimizing media delivery." name="twitter:description"/>
<link href="blog.css" rel="stylesheet"/>
<link href="https://www.anuragg.in/favicon.ico" rel="icon" type="image/x-icon"/>
</head>
<body>
<div class="wrapper">
<div class="docs-nav-container">
<ul class="docs-nav">
<li>
<a href="https://www.anuragg.in"><strong>Home</strong></a>
</li>
</ul>
</div>
<div class="docs-content">
<h1>
 Automating Website Content: A Comparison between Client-Side and Server-Side Automation
</h1>
<script src="https://cdn.dashjs.org/latest/dash.all.min.js">
</script>
<!-- <figure>
      <video class='videoPlayer' controls>
        <source src='https://in2eco.com/poi/videos/dash/32/timelapse/output.mpd' type='application/dash+xml' />
      </video>
    </figure> -->
<script>
 // Select all video elements with the class 'videoPlayer'
      var videos = document.querySelectorAll(".videoPlayer");
    
      // Initialize each video player with dash.js
      videos.forEach(function(video) {
          var player = dashjs.MediaPlayer().create();
          player.initialize(video, null, true);
      });
</script>
<h2>
 Overview
</h2>
<p>
 This article compares client-side and server-side automation of website content.
</p>
<h2>
 Prerequisite
</h2>
<p>
<strong>
  Mandatory:
 </strong>
 Website design using HTML, CSS, Javascript and PHP.
</p>
<p>
<strong>
  Flexible:
 </strong>
 Basic knowledge of search engines and crawlers.
</p>
<!-- ************************ SECTION: APPLICATION ************************ -->
<h2>
 Search Engines and Crawlers
</h2>
<p>
 A search engine indexes web page and ranks them. Search engines use crawlers to discover new web pages and contents. Crawling web pages on internet is equivalent to traveling in real world. Crawlers are resource-constrained. Therefore, most crawlers only discover static content.
</p>
<h2>
 Automating Website Content on the Client Side
</h2>
<p>
 There are several ways to to automatically generate content for a website on the client side; the most popular being Javascript. Common use cases for client-side automation includes: adjusting CSS property, lazy image loading, and adding content where crawlability by search engines is not important.
</p>
<figure>
<img alt="Static website using HTML, CSS and Javascript. All the files are transferred from the server to the client followed by automatic content generation using Javascript. The automated content generated by Javascript is not discoverable by resource-constrained crawlers." src="https://www.anuragg.in/../images/blog/automating_website_content/clientside.png"/>
<figcaption>
  Static website using HTML, CSS and Javascript. All the files are transferred from the server to the client followed by automatic content generation using Javascript. The automated content generated by Javascript is not discoverable by resource-constrained crawlers.
 </figcaption>
</figure>
<h3>
 Automating Website Content on the Server Side
</h3>
<p>
 There are several ways to to automatically generate content for a website on the server sider; the most popular being PHP. Server-side automation has superior capabilities compared to client-side automation. Common use cases for server-side automation includes: adding content where crawlability by search engines is not important, customizing content based on stored individual user preference.
</p>
<figure>
<img alt="Dynamic website using HTML, CSS, Javascript and PHP. Server-side processing using PHP automates addition of content on the server side before delivering it to the content. The automated content generated by PHP is discoverable by resource-constrained crawlers." src="https://www.anuragg.in/../images/blog/automating_website_content/serverside.png"/>
<figcaption>
  Dynamic website using HTML, CSS, Javascript and PHP. Server-side processing using PHP automates addition of content on the server side before delivering it to the content. The automated content generated by PHP is discoverable by resource-constrained crawlers.
 </figcaption>
</figure>
<h3>
 Considerations for Search Engine Discovery: Crawler-Friendly Websites
</h3>
<p>
 Depending on how one automates content on website, one may need additional steps to make the content on their website discoverable by search engines. For client-side automation of website content, pre-rendering of content is required for discovery. Automation can also be used for efficient delivery of content, for e.g. lazy loading of image, and DASH video streaming. These automation prevents media discovery by search engines; one can make the media discoverable as follows:
 <ul>
<li>
   Use &lt;noscript&gt; tags to show media to crawlers without lazy loading or DASH streaming
  </li>
<li>
   Use meta tags to direct crawlers to a crawler-friendly website.
  </li>
<li>
   For websites designed using HTML, CSS, and Javascript, use pre-rendering to generate crawler-friendly static websites.
  </li>
</ul>
</p>
<h2>Author</h2>
<p><a href="https://www.anuragg.in">Anurag Gupta</a> is an M.S. graduate in Electrical and Computer Engineering from Cornell University. He also holds an M.Tech degree in Systems and Control Engineering and a B.Tech degree in Electrical Engineering from the Indian Institute of Technology, Bombay.</p>
</div>
<script src="blog.js"></script>
</div></body>
</html>
