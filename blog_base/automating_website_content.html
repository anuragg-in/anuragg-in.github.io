<h1>Generating Website Content with Scripting: A Comparison between Client-Side and Server-Side Automation</h1>
<script src="https://cdn.dashjs.org/latest/dash.all.min.js"></script>
<!-- <figure>
  <video class='videoPlayer' controls>
    <source src='https://in2eco.com/poi/videos/dash/32/timelapse/output.mpd' type='application/dash+xml' />
  </video>
</figure> -->
<script>
  // Select all video elements with the class 'videoPlayer'
  var videos = document.querySelectorAll(".videoPlayer");

  // Initialize each video player with dash.js
  videos.forEach(function(video) {
      var player = dashjs.MediaPlayer().create();
      player.initialize(video, null, true);
  });
</script>
<h2>Overview</h2>
<p>This article compares client-side and server-side scripts for generating website content.</p>
<h2>Prerequisite</h2>
<p><strong>Mandatory:</strong> Website design using HTML, CSS, Javascript and PHP.</p>
<p><strong>Flexible:</strong> Basic knowledge of search engines and crawlers.</p>
<!-- ************************ SECTION: APPLICATION ************************ -->
<h2>Search Engines and Crawlers</h2>
<p>A search engine indexes web page and ranks them. Example: Duckduckgo, Google, Bing, Yahoo, Yandex, etc. Search engines use crawlers to discover new web pages and contents. Crawling web pages on internet is equivalent to traveling in real world. Crawlers are resource-constrained. Therefore, most crawlers only discover static content, i.e., content generated immediately after downloading files from the server.</p>
<h2>Scripts for Generating Website Content</h2>
<p>Scripts are used to make a website user-friendly while reducing coding overhead. Some common use cases for scripting are:
  <ul>
    <li>Lazy loading using client-side scripting</li>
    <li>Loading an interlaced JPEG image using client-side scripting</li>
    <li>Pagination and infinite scrolling using client-side scripting with/without server-side scripting</li>
    <li>DASH streaming using client-side and server-side scripting</li>
    <li>Personalization like CSS property and user-specific content using server-side and/or client-side scripting</li>
  </ul>
</p>
<h2>Generating Website Content on the Client Side</h2>
<p>There are several ways to generate website content on the client side, the most popular being Javascript. Website content generated by client-side scripting should be limited  to content where crawling by search engines is not important.</p>
<figure>
  <img alt='client_side' src='../images/blog/automating_website_content/clientside.png'/>
  <figcaption>Static website using HTML, CSS and Javascript. Client-side scripts are executed after delivering the files from the server to the end user. The content generated by client-side scripts are not discoverable by resource-constrained crawlers.</figcaption>
</figure>
<h3>Generating Website Content on the Server Side</h3>
<p>There are several ways to generate website content on the server side, the most popular being PHP. Website content generated by server-side scripts are discoverable by crawlers. Server-side scripting is also useful in personlizing content for individual users.</p>
<figure>
  <img alt='server_side' src='../images/blog/automating_website_content/serverside.png'/>
  <figcaption>Dynamic website using HTML, CSS, Javascript and PHP. Server-side scripts are executed on the servers before the website is delivered to the end user. The content generated by server-side scripts are discoverable by resource-constrained crawlers.</figcaption>
</figure>
<h2>Considerations for Search Engine Discovery: Crawler-Friendly Websites</h2>
<p>Depending on scripting mode for generating website content, one may need additional steps to make the content on their website discoverable by search engines. For client-side scripting, pre-rendering is required for discovery by crawlers. Scripting is also be used for efficient delivery of content, for e.g. lazy loading of image, and DASH video streaming. Though this prevents media discovery by crawlers; one can make them discoverable as follows:
<ul>
  <li>Use &lt;noscript&gt; tags to show media to crawlers without lazy loading or DASH streaming</li>
  <li>Use meta tags to direct crawlers to a crawler-friendly website.</li>
  <li>For websites designed using HTML, CSS, and Javascript, use pre-rendering to generate crawler-friendly static websites.</li>
</ul>
</p>

<h2>Crawlers Overhead on Bandwidth</h2>
<p>Crawlers increase load on servers. Therefore, depending on how resource-intensive a website is, one may need to trade-off between discoverability by crawlers and bandwidth conservation. There are several ways to reduce bandwidth overhead by crawlers:
<ul>
  <li>Adjust the crawling frequency</li>
  <li>Schedule time slots for crawlers so that peak time bandwidth demand is mitigated</li>
  <li>Use robots.txt to limit crawlers' access to resource-intensive webpages</li>
</ul>
</p>
